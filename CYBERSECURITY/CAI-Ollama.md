# Running CAI with Open-Source Models via Ollama and Using it for CTF Labs

## Configuring CAI with Ollama (Local Models)

**CAI** (Cybersecurity AI) supports using local open-weight models through an OpenAI-compatible API. **Ollama** provides a local server that can host models like LLaMA-2 or Qwen, and CAI can connect to it. To set this up, you need to configure a few environment variables and ensure the API endpoints align:

* **Install and Launch Ollama:** Make sure Ollama is running and you have pulled the desired model (e.g. Qwen or LLaMA). Ollama listens by default on `http://127.0.0.1:11434` (unless configured otherwise).

* **Set Environment Variables:** Create a `.env` file in the CAI directory (or export env vars) with at least:

  ```bash
  OPENAI_API_KEY="sk-1234"          # (a dummy API key, just to satisfy CAI's requirement)  
  OLLAMA_API_BASE="http://127.0.0.1:11434/v1"  
  ```

  The **`OLLAMA_API_BASE` must include the `/v1` path**. CAI’s backend uses the OpenAI client library which appends its own path (`/chat/completions`), whereas Ollama’s OpenAI-compatible mode expects a base URL ending in `/v1`. If you omit the `/v1`, you’ll hit 404 errors. In fact, this misalignment was a known issue and the CAI team advises adding the `v1` in the base URL to resolve it. (For example, use `http://localhost:11434/v1` instead of just `http://localhost:11434`.)

* **Specify the Model:** By default, CAI will send requests to the OpenAI API (or the Ollama proxy) with a model name. You can set the model via the `CAI_MODEL` environment variable or within CAI’s interactive commands. In local/Ollama usage, this model name should match one that Ollama serves. For instance, if you have a Qwen 14B model, you might set `CAI_MODEL="qwen2.5:14b"` or select it in the UI. CAI supports **300+ models** across providers (OpenAI, Anthropic, etc.), and specifically lists *“Ollama: `Qwen2.5 72B`, `Qwen2.5 14B`, etc.”* as examples. So Qwen-14B is one of the tested open models. Ensure the name matches exactly what Ollama expects (check Ollama’s model catalog naming).

* **Launching CAI:** Once the .env is configured, simply run `cai`. The CLI will start and you’ll see the ASCII art and version banner, then a prompt `CAI>`. CAI will now route its LLM queries to the local Ollama server using your specified model. If everything is set up correctly, you shouldn’t get API errors. (If you *do* see errors like `litellm.APIConnectionError: 'name'` or JSON unmarshal errors, it usually means the API base wasn’t correct or Ollama had a compatibility bug. Double-check the `/v1` part and that Ollama is running the expected version.)

**Troubleshooting Ollama Integration:** In some environments (e.g. using Docker containers or on macOS), you might need extra tweaks. The CAI FAQ notes that if you run CAI in a container or VM, ensure host networking is enabled so it can reach the Ollama service, especially on Docker for Mac. Also, use the `curl -v http://<ollama-host>:11434/v1` to verify connectivity if unsure. Once configured, CAI treats the local model just like an OpenAI model – you’ll even see token counts and a `$0.0000` cost line (which you can ignore, since local models don’t actually incur cost).

## Using CAI: Agents, Prompts, and Workflows

CAI operates with an **agent-based, ReACT pattern** for penetration testing tasks. When you start CAI, it typically loads a default **Red Team/CTF agent** – this agent is equipped to perform recon, exploitation, and other offensive tasks using tools like nmap, nikto, metasploit, etc., as needed. You interact with CAI via natural language prompts at the `CAI>` prompt, and the agent will reason about the task and execute tools autonomously. Here’s how to use it effectively:

* **Initial Prompt (Scenario Setup):** Provide a clear starting instruction that defines the target and goal. For example, you might type:

  ```plaintext
  Target IP: 192.168.3.10, perform a full network scan
  ```

  This is similar to the example in the docs: *“Target IP: 192.168.3.10, perform a full network scan.”*. Given such a prompt, the agent will interpret that it should enumerate the network services on that IP. In the UI, you’ll see something like **“CTF agent – Executing Command: nmap 127.0.0.1 …”** as it begins using the Nmap tool. In the example above, the agent indeed started an Nmap scan as the first step.

* **Autonomous Actions:** CAI’s agent will go through a cycle of *think → act → observe*, per the ReACT pattern. It uses the LLM to decide on an action, then invokes a tool. For instance, after an initial port scan, it might reason “no ports found, maybe scan deeper” and run a more aggressive Nmap scan (as you observed, it tried different Nmap flags repeatedly). This autonomy is powerful – the agent can chain multiple steps – but it can sometimes lead to it getting stuck in a loop or focusing narrowly (more on that in a moment). You can always watch the tool outputs in real time; CAI prints the command results in the console.

* **Listing and Switching Agents:** CAI is modular – it actually has multiple agents for different purposes (red team, blue team, single-tool test agents, etc.). For offensive CTF work, the **default “CTF agent”** (Red Team agent) is what you want. If you’re curious, you can see all available agents by typing the command `/agent` at the CAI prompt. This will show a menu or list of agents. The Red Team agent is the one that uses a swarm of tools for hacking tasks. (There is also a “one\_tool\_agent” which executes only a single tool per turn, useful for debugging or simpler operations, but it won’t solve multi-step challenges by itself.) In general, you do **not** need to manually switch agents for HackTheBox-style challenges – stick with the default unless you have a specific reason to try a different approach.

* **Understanding the Output Interface:** The bottom status bar shows tokens and cost, which is mostly relevant if using paid APIs – for local models it will just show \$0.0000 and token counts. More importantly, pay attention to the content above: CAI prints each reasoning step as **“╭─ CTF agent - …”** followed by either a tool execution or a thought. Tool outputs are shown in boxed sections. This transparency (full decision and tool trace) is by design – you can see exactly what the AI is doing and thinking.

* **Human in the Loop (HITL) Interaction:** One of CAI’s core principles is that it’s *semi*-autonomous – you can and should intervene when needed. If the agent is stuck or you have an idea for the next step, you can press **Ctrl+C twice** to activate the HITL mode. This interrupts the agent’s autonomous loop and lets you enter a prompt to the agent directly (you essentially become part of the conversation, giving the agent new information or commands). For example, if you notice it’s looping over Nmap scans, you might hit Ctrl+C and say, *“No open ports found by Nmap. Try a different approach, like scanning the filesystem for sensitive files.”* Once you submit your input, the agent (with its existing history + your new instruction) will resume and incorporate your guidance. HITL is extremely useful to steer the AI when it’s off-track.

* **Built-in Commands:** CAI’s REPL has some special slash commands. We mentioned `/agent` to list agents. Similarly, `/model` lets you swap the model on the fly (if you wanted to compare outputs between, say, Qwen and another model). `/help` will show a help menu of commands, and `/config` will display current configuration like which model and agent are active. These are good to know, but for typical use you might not need them often.

## Avoiding Loops and Improving Agent Performance

It’s not uncommon to see the agent **repeating the same command or getting stuck** (as you experienced with Nmap). There are a few reasons this can happen, especially with open-source models that might not be as finely tuned as GPT-4:

* **Model Reasoning Limitations:** The local model (e.g. Qwen 14B) might sometimes lack the nuanced understanding to know when to stop scanning or when to pivot strategies. In your case, it kept running Nmap with different flags on `127.0.0.1`. This could be the model’s attempt to be thorough (scanning all ports, using service detection, etc.) because it didn’t find anything – essentially it didn’t “realize” that further Nmap scans won’t reveal new info. This is partly a logic issue that better prompting or model tuning may improve in the future.

* **litellm Completion Errors:** CAI uses the `litellm` library to handle LLM outputs. There have been reports that when an error occurs during the LLM completion (for instance, some JSON or function-call output that Ollama couldn’t parse), **the agent can go into an infinite loop** trying to recover. In Issue #228, the developer noted that such errors cause the agent to never receive a proper stop signal, so it keeps executing the last action repeatedly. If you suspect a bug like this (especially if using a newer model or seeing stack traces), updating CAI to the latest version might help, as the team is actively fixing these. Also ensure your Ollama is up-to-date, since some issues were traced to Ollama’s handling of certain outputs.

* **Lack of Context/State:** Remember that CAI’s agents are *stateless between turns* (each interaction, it considers the dialogue history but doesn’t maintain a persistent memory unless you use the memory extension). If the model isn’t instructed well, it might not “remember” that it already scanned the same port range moments ago. The CAI prompt templates do include the interaction history as context, but depending on model size and context length, it might still repeat itself. Using the **brief mode** (`CAI_BRIEF=true`) can sometimes help by keeping prompts concise, though that mode is more about output verbosity than reasoning loops.

**How to break the loop:** Utilize HITL as mentioned. When you see the agent doing unproductive repeats (like scanning the same host 5th time), intervene: *“You have already scanned all ports and found nothing. Move on to the next step or try a different approach (e.g., enumerate web directories or check for default credentials).”* The model should then adjust course. In testing, users found that a small nudge can snap the agent out of a cycle and onto a fresh path. This is aligned with CAI’s design – human oversight is expected to guide the AI out of blind spots.

**Why it didn’t search the filesystem:** You also asked why the agent didn’t run a command to search the local filesystem when you prompted it. In the log excerpt, when you typed `find sensitive files`, the agent bizarrely kicked off another Nmap scan on `127.0.1.1`. The likely reason is **contextual misunderstanding** – the agent (perhaps due to how the prompt template is structured or the model’s training) interpreted “find sensitive files” as an instruction to *enumerate something on the network* (maybe it latched onto the word *find* and went into recon mode again). Another possibility is that the agent didn’t have a concept of having “shell access” to search files at that point. Unless the scenario is set such that the AI thinks it has landed on the target system (via exploitation), it will stick to external recon. By default, the CTF agent treats the target as an external system to probe; it won’t run `find / -name "*password*"` on your local machine unless it believes it’s *inside* the target.

To get file search behavior, a typical flow would be: CAI exploits a vulnerability, *then* spawns a sub-agent or tool to search the target’s filesystem. CAI does have capabilities to run shell commands – for example, if it exploited a remote code execution, it could use the `generic_linux_command` tool to run things like `ls` or `grep` on the target. But in your run, no exploit was found (nothing to give it shell access), so it never got to that stage. If you want to force a local file search (for testing), you could manually use HITL to simulate that an exploit occurred: e.g., *“Assume you have a shell on the machine. Now search for flags in /home.”* This might prompt the agent to use `generic_linux_command(find /home -type f -name flag*)`. Without that context, the agent stayed in recon mode and thus the only “find” it knew was perhaps “find open ports/services” (hence another Nmap run).

**Summary tips to avoid looping:** Keep an eye on the agent’s reasoning. If it’s cycling, intervene with a new instruction or use the `/agent` command to possibly switch to a simpler agent for one step (e.g., run a single command manually). The CAI team is aware of looping behavior – in fact, they noted “errors during completion causing infinite loops” as an open issue – so newer versions may handle this more gracefully. Until then, proactive HITL guidance is the way to go. Fortunately, every time you break in with HITL, the **agent retains full context of previous steps** (the history is preserved), so you’re not resetting progress – you’re just helping it along.

## Choosing a Competent Model (Qwen vs Others)

Using **Qwen** via Ollama is a popular choice – Qwen-14B is a relatively strong general model and the CAI docs explicitly mention Qwen variants as supported. If Qwen is working “okay” but not great, you have a few alternatives to consider:

* **Llama 2 (70B or 34B):** If you have the compute resources (70B model is heavy), Llama 2 Chat models or fine-tuned variants might perform better in following complex instructions. Many community fine-tunes exist (e.g., WizardLM, CodeLlama for coding tasks, etc.) that could improve certain behaviors. They can be served via Ollama similarly. Some users have tried a “Llama 3.1 70B” model with CAI (likely a fine-tune referred to in issues) and had mixed results, but generally larger models = more coherent tool use.

* **DeepSeek or Other Security-Tuned Models:** The CAI team references models like *DeepSeek V3* in their papers. DeepSeek might be an internally fine-tuned model for security tasks. If it’s available open-source (some DeepSeek model checkpoints are on HuggingFace), it could potentially understand pentesting steps better. In Issue #76, a user tried `"deepseek-r1:7b"` and some model called `"deepcoder:latest"` via Ollama. The results weren’t explicitly stated, but the fact these models exist suggests the community is building security-focused LLMs. You might keep an eye out for any CAI-specific model releases.

* **GPT-4 (OpenAI API):** This isn’t open-source, but it’s worth noting: GPT-4 was used in CAI’s development and unsurprisingly performs excellently at these tasks. If you ever need maximum competence and are willing to use a paid API, GPT-4 (denoted as `GPT-4o` or similar in CAI) would likely solve challenges more autonomously. In the CAI benchmark, closed models like *Gemini* and *Claude 3.7* were tested too. However, since your focus is on open models, you’re basically trading some raw “intelligence” for cost-free local operation. Qwen-14B is among the top open models, so it’s a reasonable pick.

* **Model Settings:** Whichever model you use, consider the context length and temperature. CAI’s `.env` or config might allow setting these (for OpenAI models, `MAX_TOKENS` and `TEMPERATURE` can be set; for Ollama models, you might configure them in Ollama). A longer context window (if the model supports it) means CAI can remember more past actions – helpful for long CTF exercises. Temperature controls randomness: a slightly lower temperature (e.g. 0.2-0.5) could make the agent more deterministic in following the plan, which *might* reduce off-track behavior. If the model is too “creative” it might wander, but too low and it could get stuck in repetitive loops. You may need to experiment to find a sweet spot for your model. The example of a custom Modelfile for a CAI assistant set Qwen’s temperature to 0.7 for balanced behavior.

**Bottom line:** Qwen-14B is a solid starting point (the CAI team achieved good results with an even larger Qwen-72B, which not everyone can run). If you find Qwen struggling with certain tasks, you could try Llama-2 13B/70B models fine-tuned for instruction-following, or wait for community models explicitly tuned for pentesting. Always update your CAI framework to the latest version too – it may include model-specific fixes or prompt improvements that enhance compatibility with local models.

## Applying CAI to HackTheBox and CTF Challenges

One of CAI’s primary goals is to **solve real-world CTFs and bug bounty challenges**. In fact, CAI has proven itself in competition, ranking among the top AI agents in HackTheBox events and outperforming human teams in speed on many challenges. Here are some tips to effectively use CAI on HackTheBox (HTB) machines or similar CTF labs:

* **Environment Setup for HTB:** If you’re attacking a HackTheBox machine, you’ll typically connect to the HTB VPN so the target IP is reachable. CAI doesn’t need to know about the VPN; you just give it the target IP (e.g., 10.10.11.123) in the prompt. However, if the target is only accessible from a tun0 interface, ensure your machine (where CAI is running) can reach it (standard practice for HTB). You might also utilize the `CTF_SUBNET` and `CTF_IP` env variables if you’re using CAI’s built-in integration for its own Dockerized CTF environments – but for HTB, that’s not necessary; just treat it as an external target.

* **Start with Recon:** CAI excels at the tedious parts of recon. Let it run its course with Nmap and other enumeration. For a web challenge, it may use tools like `gobuster` or `whatweb`. For a binary pwn challenge, it might try `checksec` or static analysis tools if those are in its toolset (some tools like Ghidra or radare might not be integrated by default, but CAI can use Python for scripting simple analysis). The key is to describe the challenge enough so the agent picks the right approach. For example, for a web app, you might mention “running a web service” in the prompt; for a binary challenge, mention “there is a binary file to analyze.”

* **Guide it with Hints (if needed):** While CAI can be autonomous, in practice you’ll often achieve the solution faster by giving it slight nudges rather than letting it brute-force every possibility. This is the **Human-AI collaboration** aspect. For instance, if you know the machine likely has a WordPress site (maybe the Nmap found port 80 open with a WP theme), you can HITL and tell it “It’s a WordPress site – enumerate plugins and themes for vulnerabilities.” The agent will then focus on that, saving time over trying random dirs or exploits. In the CAI team’s own HTB runs, they did allow some human feedback to steer the AI; this hybrid approach was key to their success.

* **Privilege Escalation:** Once CAI finds a way in (say it exploits a web vulnerability to get a reverse shell), you may need to prompt it to stabilize the shell and then enumerate for privilege escalation. CAI is aware of common privesc techniques (checking sudo permissions, SUID binaries, kernel exploits, etc.) because these are documented patterns. You can simply say, “Now that you have user access, find a path to root.” The agent might run `linPEAS` or `sudo -l` or other commands via its tools. Watch what it does – if it misses something (like it checks groups but not cron jobs), you can intervene and direct it to that.

* **Finding Flags:** For HackTheBox specifically, the “flags” are typically at known locations (e.g. `/home/username/user.txt` and `/root/root.txt`). CAI doesn’t inherently know the flag location, but it knows the concept of looking for sensitive info. You can instruct it explicitly: “Look for any files named *flag* or \*.txt that might contain the flag.” If the agent has shell access on the box, it can then run the appropriate find/grep. If it outputs the flag, great! If it only outputs the path or some encoded string, you may have to retrieve it manually – *be cautious here*: don’t accidentally reveal your real HTB flag to any online system. Since CAI is running locally with your model, it’s fine – no data is sent out – but as a rule, treat flags as sensitive until you submit them.

* **Iterate with Memory (Advanced):** CAI logs every run (e.g., `logs/cai_<session_id>.jsonl`). There’s a feature to generate a **memory summary** from a successful run and feed it into a new run as prior knowledge. This can be useful if, say, CAI partially solved a challenge but you had to stop or if you want it to tackle a similar machine with knowledge from previous ones. The process involves running a script `tools/2_jsonl_to_memory.py` to distill a log into an “episodic memory”, and then setting `CAI_MEMORY` and `CAI_MEMORY_COLLECTION` env vars on the next run. This is a bit experimental, but it’s there. For normal HTB usage, you might not need this unless you’re doing a research project with CAI. Still, it’s good to know CAI can leverage past experience.

* **Expect to still use your expertise:** CAI is not a “push-button root everything” magic (not yet!). Think of it as a very fast junior pentester. It will enumerate swiftly (in their paper, CAI solved some HTB challenges **346× faster than humans on average** in terms of time taken, especially excelling at things like crypto or forensics that involve crunching data). But it might overlook subtle logic or misconfigure a payload. Your role is to watch, interpret results, and give high-level direction. This synergy can drastically speed up solving; e.g., CAI can crunch through a tedious task in seconds which might take you an hour, and then you provide the insight on what that finding means. In the “AI vs Human” CTF, CAI was the best AI team and even ranked in the top 20 overall (human teams included), but it did so with some human oversight in the loop. Leverage the AI’s strength (speed and breadth) and your own (intuition and experience) together.

* **Stay within Rules:** When using CAI on platforms like HackTheBox, ensure you’re not violating any rules. HTB forbids automated scanners on certain networks or excessive traffic. CAI, when unleashed, can generate a lot of traffic (for example, a full `nmap -p- -sV` on all ports, or brute forcing directories). Use rate limits or scope control if needed. You can modify tool parameters (for instance, you could edit the agent’s tools to add `--min-rate 100` or such for Nmap as it was doing). Generally, free HTB machines are meant to be scanned, but just be mindful of not DoSing a target with AI speed.

## Conclusion

In summary, **to run open-source models with CAI via Ollama**, make sure to configure the OLLAMA API endpoint correctly (including the `/v1` path to avoid misalignment issues). With Ollama up, you can use a capable model like Qwen-14B, which CAI’s developers have found effective for cybersecurity tasks. Once configured, use CAI’s CLI to initiate tasks by describing your target and goal. The default CTF/RedTeam agent will then autonomously perform recon and attacks, calling tools like Nmap on its own. Keep an eye on its actions: if it **loops the same command** or seems stuck, intervene with the HITL mechanism to guide it – this is expected and part of how CAI is designed (human-plus-AI collaboration). Over time, as you and the agent “learn” each other’s patterns, you’ll be able to solve even complex HackTheBox challenges more efficiently. In fact, CAI has demonstrated the ability to solve challenges across web, crypto, forensics, and more in a fraction of the time it takes humans, and it even achieved top rankings in HTB competitions – so with a bit of tuning and teamwork between you and the AI, you can **complete CTF labs faster and with less manual toil**. Good luck, and enjoy hacking with your new AI partner!

**Sources:**

* CAI official documentation and FAQ (Alias Robotics)
* CAI GitHub issues and discussions on Ollama integration
* Alias Robotics blog – *CAI framework overview* (details multi-LLM support and design)
* *CAI: Open Bug Bounty-Ready Cybersecurity AI* research paper (performance results on CTFs/HTB)
